from elasticsearch import Elasticsearch
from langchain.output_parsers.json import SimpleJsonOutputParser
from langchain_community.chat_models import ChatOpenAI
from langchain_core.pydantic_v1 import BaseModel

from .elastic_index_info import get_indices_infos
from .prompts import DSL_PROMPT

print(DSL_PROMPT)

import json

# Setup Elasticsearch
# This shows how to set it up for a cloud hosted version

# # Password for the 'elastic' user generated by Elasticsearch
# ELASTIC_PASSWORD = "..."
#
# # Found in the 'Manage Deployment' page
# CLOUD_ID = "..."
#
# # Create the client instance
# db = Elasticsearch(cloud_id=CLOUD_ID, basic_auth=("elastic", ELASTIC_PASSWORD))

with open("../config.json") as config_file:
    config = json.load(config_file)

CLOUD_ID = config["lee_cloud"]["Cloud_id"]
API_KEY = config["lee_cloud"]["API_KEY"]

db = Elasticsearch(
    cloud_id=CLOUD_ID,
    api_key=API_KEY
)

# Specify indices to include
# If you want to use on your own indices, you will need to change this.
INCLUDE_INDICES = ["customers"]

# With the Elasticsearch connection created, we can now move on to the chain
OPENAI_API_KEY = "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"
_model = ChatOpenAI(temperature=0, model="gpt-3.5-turbo", openai_api_key=OPENAI_API_KEY)

chain = (
    {
        "input": lambda x: x["input"],
        # This line only get index info for "customers" index.
        # If you are running this on your own data, you will want to change.
        "indices_info": lambda _: get_indices_infos(
            db, include_indices=INCLUDE_INDICES
        ),
        "top_k": lambda x: x.get("top_k", 10),
    }
    | DSL_PROMPT
    | _model
    | SimpleJsonOutputParser()
)


# Nicely typed inputs for playground
class ChainInputs(BaseModel):
    input: str
    top_k: int = 5


chain = chain.with_types(input_type=ChainInputs)
